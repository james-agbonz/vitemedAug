{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd2a5a093df426abc5f59a2d4129c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317\n"
     ]
    }
   ],
   "source": [
    "from model import ModelFx\n",
    "from dataset_service.isic_multimodal.dataset import ISIC_MultiModal_DataModule\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "device = torch.device('cuda')\n",
    "# device = torch.device('mps')\n",
    "\n",
    "model_list = []\n",
    "dm_list = []\n",
    "for i in tqdm(range(5)):\n",
    "    model_list.append(\n",
    "        ModelFx(i).model.to(device).eval()\n",
    "    )\n",
    "    dm = ISIC_MultiModal_DataModule(\n",
    "        img_size=224,\n",
    "        batch_size=32,\n",
    "        data_loader_kwargs=dict(num_workers=8),\n",
    "        dataset_init_kwargs=dict(\n",
    "            fold=i\n",
    "        ),\n",
    "        suppress_aug_info_print=True\n",
    "    )\n",
    "    dm.setup('val')\n",
    "    train_size = int(0.8 * len(dm.val))\n",
    "    test_size = len(dm.val) - train_size\n",
    "\n",
    "    # Split the dataset\n",
    "    train_dataset, test_dataset = random_split(dm.val, [train_size, test_size])\n",
    "    test_dataset.__se__ = None\n",
    "    dm.val = test_dataset\n",
    "    dm_list.append(dm)\n",
    "\n",
    "print(dm_list[0].val.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty, General Eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b323f959734fe08ca717f10a647e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 0:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a71855c5f8449e927cfc6aefffd591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 1:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69ceadd43d940559929d07c5da40cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 2:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8744ea7b060f47d0861648ae294c7160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 3:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff205b1491e4bb4b587ef429051e5f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 4:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch_uncertainty.metrics.classification import BrierScore\n",
    "from evaluation_service.model_eval.eval import get_brier_score\n",
    "\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassPrecision, MulticlassRecall, MulticlassF1Score\n",
    "\n",
    "\n",
    "rs_data = []\n",
    "\n",
    "for fold in range(5):\n",
    "    model = model_list[fold]\n",
    "    data_module = dm_list[fold]\n",
    "\n",
    "    accuracy = MulticlassAccuracy(\n",
    "        num_classes=data_module.num_classes).to(device)\n",
    "    precision = MulticlassPrecision(\n",
    "        num_classes=data_module.num_classes).to(device)\n",
    "    recall = MulticlassRecall(num_classes=data_module.num_classes).to(device)\n",
    "    f1 = MulticlassF1Score(num_classes=data_module.num_classes).to(device)\n",
    "    brier_score = BrierScore(\n",
    "        num_classes=data_module.num_classes\n",
    "    ).to(device)\n",
    "\n",
    "    for x, y in tqdm(data_module.val_dataloader(), desc=f'Fold {fold}'):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        with torch.no_grad():\n",
    "            brier_score, pred, softmax_pred = get_brier_score(\n",
    "                model, x, y, brier_score, data_module.num_classes)\n",
    "            # Convert predictions to numpy array\n",
    "            predicted_classes = pred.argmax(dim=1).cpu().numpy()\n",
    "            true_classes = y.cpu().numpy()\n",
    "\n",
    "            # Calculate metrics\n",
    "            accuracy.update(pred, y)\n",
    "            f1.update(pred, y)\n",
    "            recall.update(pred, y)\n",
    "            precision.update(pred, y)\n",
    "\n",
    "            # print(bs)\n",
    "    rs_data.append({\n",
    "        'fold': fold,\n",
    "        'bs': brier_score.compute().item(),\n",
    "        'accuracy': accuracy.compute().item(),\n",
    "        'f1': f1.compute().item(),\n",
    "        'recall': recall.compute().item(),\n",
    "        'precision': precision.compute().item(),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>bs</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.252084</td>\n",
       "      <td>0.700810</td>\n",
       "      <td>0.730070</td>\n",
       "      <td>0.700810</td>\n",
       "      <td>0.769346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.203009</td>\n",
       "      <td>0.711097</td>\n",
       "      <td>0.702678</td>\n",
       "      <td>0.711097</td>\n",
       "      <td>0.710797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.223311</td>\n",
       "      <td>0.744245</td>\n",
       "      <td>0.726691</td>\n",
       "      <td>0.744245</td>\n",
       "      <td>0.721449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.239552</td>\n",
       "      <td>0.726333</td>\n",
       "      <td>0.695942</td>\n",
       "      <td>0.726333</td>\n",
       "      <td>0.682797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.245369</td>\n",
       "      <td>0.712120</td>\n",
       "      <td>0.720660</td>\n",
       "      <td>0.712120</td>\n",
       "      <td>0.734468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold        bs  accuracy        f1    recall  precision\n",
       "0     0  0.252084  0.700810  0.730070  0.700810   0.769346\n",
       "1     1  0.203009  0.711097  0.702678  0.711097   0.710797\n",
       "2     2  0.223311  0.744245  0.726691  0.744245   0.721449\n",
       "3     3  0.239552  0.726333  0.695942  0.726333   0.682797\n",
       "4     4  0.245369  0.712120  0.720660  0.712120   0.734468"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(rs_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grad-CAM, SHAP, LIME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.xai_service.general_xai.general_xai import grad_cam, shap_map, lime_map\n",
    "from xai_service.general_xai.gradient_methods import guided_absolute_grad\n",
    "from backend_central_dev.utils import plotting_utils\n",
    "from backend.evaluation_service.xai_eval.rcap import batch_rcap\n",
    "from backend_central_dev.utils import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d16fbd61ca934a4f92000c90d9948239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 0:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ef13275d7046c99b8c862e6760cff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 1:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7454a0762f84486aa87f9949ed394c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 2:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed04e4fea054881a7f795eebdb03ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 3:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436c261a57f64205b127df0f2744dd6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 4:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = [\n",
    "    dict(\n",
    "        gag_rs=[],\n",
    "        grad_cam_rs=[],\n",
    "        shap_rs=[],\n",
    "        lime_rs=[]\n",
    "    )\n",
    "    for i in range(5)\n",
    "]\n",
    "\n",
    "for fold in range(5):\n",
    "    model = model_list[fold]\n",
    "    data_module = dm_list[fold]\n",
    "    with tqdm(total=len(data_module.val_dataloader()), desc=f\"Fold {fold}\") as pbar:\n",
    "        for x, y in data_module.val_dataloader():\n",
    "            # s = 20\n",
    "            # e = s + 1\n",
    "            # x = x.to(device)[s:e]\n",
    "            # y = y.to(device)[s:e]\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # plotting_utils.plot_hor([xx.transpose(1, 2, 0)\n",
    "            #                         for xx in data_utils.denormm_i_t(x.clone()).cpu().numpy()])\n",
    "\n",
    "            # cam_map = grad_cam(model, x, y, getattr(model.enet.blocks, '6'))\n",
    "\n",
    "            # plotting_utils.plot_hor([one_map.cpu().numpy()\n",
    "            #                         for one_map in cam_map])\n",
    "\n",
    "            # gag_map = guided_absolute_grad(model, x, y, num_samples=10, blur=True)\n",
    "\n",
    "            # plotting_utils.plot_hor([one_map.cpu().numpy()\n",
    "            #                          for one_map in gag_map])\n",
    "\n",
    "            # shap_values = shap_map(\n",
    "            #     model,\n",
    "            #     x,\n",
    "            #     y,\n",
    "            #     lambda i: torch.clamp(i, 0, 1).cpu(\n",
    "            #     ).numpy().transpose(0, 2, 3, 1),\n",
    "            #     (\"blur(128,128)\", (224, 224, 3)),\n",
    "            #     device,\n",
    "            #     shap_params=dict(\n",
    "            #         max_evals=500,\n",
    "            #         batch_size=20,\n",
    "            #     )\n",
    "            # )\n",
    "\n",
    "            # plotting_utils.plot_hor(shap_values)\n",
    "\n",
    "            # explanations = lime_map(\n",
    "            #     model,\n",
    "            #     x,\n",
    "            #     y,\n",
    "            #     device,\n",
    "            #     lime_params=dict(\n",
    "            #         num_samples=10,\n",
    "            #         progress_bar=True,\n",
    "            #     )\n",
    "            # )\n",
    "\n",
    "            # plotting_utils.plot_hor(explanations)\n",
    "\n",
    "            # ======== RCAP =========\n",
    "\n",
    "            # pbar.set_postfix_str(\"Grad Cam\")\n",
    "            # grad_cam_rcap = batch_rcap(model, (x, y), grad_cam, dict(\n",
    "            #     target_layers=getattr(model.enet.blocks, '6')))\n",
    "\n",
    "            # results[fold]['grad_cam_rs'].append(grad_cam_rcap)\n",
    "\n",
    "            # pbar.set_postfix_str(\"GAG\")\n",
    "            # gag_map_rcap = batch_rcap(model, (x, y), guided_absolute_grad, dict(\n",
    "            #     blur=True\n",
    "            # ))\n",
    "            # results[fold]['gag_rs'].append(gag_map_rcap)\n",
    "\n",
    "            # pbar.set_postfix_str(\"SHAP\")\n",
    "            # shap_rcap = batch_rcap(model, (x, y), shap_map, dict(\n",
    "            #     image_processor=lambda i: torch.clamp(\n",
    "            #         i, 0, 1).cpu().numpy().transpose(0, 2, 3, 1),\n",
    "            #     masker_params=(\"blur(128,128)\", (224, 224, 3)),\n",
    "            #     device=device,\n",
    "            #     norm_output=True,\n",
    "            #     # shap_params=dict(\n",
    "            #     #     max_evals=100,\n",
    "            #     #     batch_size=10\n",
    "            #     # )\n",
    "            # ))\n",
    "            # results[fold]['shap_rs'].append(shap_rcap)\n",
    "\n",
    "            pbar.set_postfix_str(\"lime\")\n",
    "            lime_rcap = batch_rcap(model, (x, y), lime_map, dict(\n",
    "                device=device,\n",
    "                lime_params=dict(\n",
    "                    num_samples=100,\n",
    "                )\n",
    "            ))\n",
    "            results[fold]['lime_rs'].append(lime_rcap)\n",
    "            pbar.update(1)\n",
    "    #         break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save('results_lime.npy', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "\n",
    "def print_rs(rs):\n",
    "    target_aggregated_rcap_keys = [\n",
    "        # 'original_pred_score',\n",
    "        # 'recovered_pred_score',\n",
    "        # 'original_pred_prob',\n",
    "        'recovered_pred_prob',\n",
    "        # 'local_heat_mean',\n",
    "        # 'local_heat_sum',\n",
    "        # 'overall_heat_mean',\n",
    "        # 'overall_heat_sum',\n",
    "        # 'all_original_pred_prob_full',\n",
    "        # 'all_recovered_pred_prob_full',\n",
    "        'overall_rcap'\n",
    "    ]\n",
    "    rs_data = []\n",
    "    for fold, fold_exp in enumerate(rs):\n",
    "        for xai_key, xai_rcap_result_of_all_batches in fold_exp.items():\n",
    "            recovered_pred_prob_list = []\n",
    "            rcap_list = []\n",
    "            visual_noize_level = []\n",
    "            for xai_rcap_result_of_one_batch in xai_rcap_result_of_all_batches:\n",
    "                recovered_pred_prob_of_batch = xai_rcap_result_of_one_batch['recovered_pred_prob']\n",
    "                recovered_pred_prob_list.append(\n",
    "                    np.array(recovered_pred_prob_of_batch).mean())\n",
    "                rcap_list.append(\n",
    "                    np.array(\n",
    "                        xai_rcap_result_of_one_batch['overall_rcap']['RCAP']).mean()\n",
    "                )\n",
    "                visual_noize_level.append(\n",
    "                    np.array(\n",
    "                        xai_rcap_result_of_one_batch['overall_rcap']['visual_noise_level']).mean()\n",
    "                )\n",
    "            # print(len(recovered_pred_prob_list))\n",
    "            # print(len(rcap_list))\n",
    "            # print(len(visual_noize_level))\n",
    "            rs_data.append({\n",
    "                'fold': fold,\n",
    "                'xai_key': xai_key,\n",
    "                'localization': np.array(recovered_pred_prob_list).mean(),\n",
    "                'rcap': np.array(rcap_list).mean(),\n",
    "                'visual_noize_level': np.array(visual_noize_level).mean()\n",
    "            })\n",
    "        break\n",
    "    display(pd.DataFrame(rs_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w8/pyvvstps3zz38md50zqcznhc0000gn/T/ipykernel_98154/3864497178.py:43: RuntimeWarning: Mean of empty slice.\n",
      "  'localization': np.array(recovered_pred_prob_list).mean(),\n",
      "/Users/yinnnyou/anaconda3/envs/computing-solution/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/var/folders/w8/pyvvstps3zz38md50zqcznhc0000gn/T/ipykernel_98154/3864497178.py:44: RuntimeWarning: Mean of empty slice.\n",
      "  'rcap': np.array(rcap_list).mean(),\n",
      "/var/folders/w8/pyvvstps3zz38md50zqcznhc0000gn/T/ipykernel_98154/3864497178.py:45: RuntimeWarning: Mean of empty slice.\n",
      "  'visual_noize_level': np.array(visual_noize_level).mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>xai_key</th>\n",
       "      <th>localization</th>\n",
       "      <th>rcap</th>\n",
       "      <th>visual_noize_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>gag_rs</td>\n",
       "      <td>0.723225</td>\n",
       "      <td>0.587459</td>\n",
       "      <td>0.811923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>grad_cam_rs</td>\n",
       "      <td>0.751662</td>\n",
       "      <td>0.552296</td>\n",
       "      <td>0.732856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>shap_rs</td>\n",
       "      <td>0.754528</td>\n",
       "      <td>0.382498</td>\n",
       "      <td>0.502029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>lime_rs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold      xai_key  localization      rcap  visual_noize_level\n",
       "0     0       gag_rs      0.723225  0.587459            0.811923\n",
       "1     0  grad_cam_rs      0.751662  0.552296            0.732856\n",
       "2     0      shap_rs      0.754528  0.382498            0.502029\n",
       "3     0      lime_rs           NaN       NaN                 NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_rs(np.load('results_cam_gag_shap.npy', allow_pickle=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlxops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
